{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana exploration notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the file name IDs and split into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "dataset_dir = '/home/ubuntu/carvana/input/data/'\n",
    "image_dir = dataset_dir + 'images'\n",
    "mask_dir = dataset_dir + 'masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 128\n",
    "img_height = 128\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4071 images belonging to 1 classes.\n",
      "Found 4071 images belonging to 1 classes.\n",
      "Found 1017 images belonging to 1 classes.\n",
      "Found 1017 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define data augmentations for training set\n",
    "data_gen_args = dict(rescale=1./255,\n",
    "                     shear_range=0.1,\n",
    "                     rotation_range=4,\n",
    "                     zoom_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     validation_split=0.2) # 20% validation set\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Create generator for training images\n",
    "train_image_generator = image_datagen.flow_from_directory(\n",
    "    image_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='training')\n",
    "\n",
    "# Create generator for training masks\n",
    "train_mask_generator = mask_datagen.flow_from_directory(\n",
    "    mask_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='training')\n",
    "\n",
    "# Create generator for validation images\n",
    "val_image_generator = image_datagen.flow_from_directory(\n",
    "    image_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='validation')\n",
    "\n",
    "# Create generator for validation masks\n",
    "val_mask_generator = mask_datagen.flow_from_directory(\n",
    "    mask_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    subset='validation')\n",
    "\n",
    "# Combine generators into single training and validation generators for model training\n",
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "validation_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(true, pred):\n",
    "    smooth = 1.\n",
    "    true_flat = K.flatten(true)\n",
    "    pred_flat = K.flatten(pred)\n",
    "    intersection = K.sum(true_flat * pred_flat)\n",
    "    score = (2. * intersection + smooth) / (K.sum(true_flat) + K.sum(pred_flat) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(true, pred):\n",
    "    loss = 1 - dice_coeff(true, pred)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
